players = read.csv("/Users/kmason/Desktop/xg_paper/EPL-Simulations/transformed_data.csv")
players = players[,-1]  # Remove the first column (index column)
# Convert categorical variables to factors
data$groups = factor(data$groups)
data$half = as.factor(data$half)
data$score_differential = as.factor(data$score_differential)
# Compute expected goals (xG) per unit time
data = data %>% mutate(xg_rate = xg / period_length)
# Remove rows where period_length is zero
no_time = which(data$period_length == 0)
data = data[-no_time,]
players = players[-no_time,]
# Split data into training (70%) and testing (30%)
train = sample(nrow(data), floor(nrow(data) * 0.7))
test = rep(0, nrow(data))
test[train] = 1
data = data %>% mutate(test = (test == 1))
# Compute fatigue metrics for offensive and defensive players
fatigue_offense = players[,which(substr(colnames(players),1,7) == "fatigue")]
fatigue_defense = players[,which(substr(colnames(players),1,7) == "opp_fat")]
data$fatigue = rowMeans(fatigue_offense) - rowMeans(fatigue_defense)
# Optimize sigma for the model
nsigma = 100
sigmas = seq(-1/100, 0.3, length.out = nsigma)
Loss = rep(0, nsigma)
for (j in c(1:nsigma)){
print(j)
sigma = sigmas[j]
# Transform player data using exponential function
exp_data = exp(players * sigma)
offense = rowSums(exp_data[,1:10])
opp_defense = rowSums(exp_data[,31:40])
weak_link_def = apply(players[,31:40],1,min)
strong_link_def = apply(players[,31:40],1,max)
weak_link_off = apply(players[,1:10],1,min)
strong_link_off = apply(players[,1:10],1,max)
diff = offense / opp_defense
# Prepare data for modeling
data_model = data %>% mutate(offense = offense, opp_defense = opp_defense,
weak_link_off = weak_link_off, weak_link_def = weak_link_def,
strong_link_off = strong_link_off, strong_link_def = strong_link_def)
# Fit weighted least squares regression model
form = formula(xg_rate ~ offense + opp_defense + half + fatigue + diff +
extra_time + home + score_differential + weak_link_off + weak_link_def)
model = lm(form, data = data_model, weights = period_length, subset = train)
# Predict and calculate loss
data_model = data_model %>% mutate(E_xg = predict(model, data_model) * period_length) %>% filter(test == 1)
Loss[j] = sum((data_model$xg - data_model$E_xg)^2)
}
# Plot testing loss vs sigma
plot(sigmas, Loss, main = "Testing Loss vs Sigma")
print(min(Loss))
#make final covaraites
sigma = sigmas[which.min(Loss)]
exp_data = exp(players*sigma)
offense = rowSums(exp_data[,1:10])
opp_defense = rowSums(exp_data[,31:40])
weak_link_def = apply(players[,31:40],1,min)
strong_link_def = apply(players[,31:40],1,max)
weak_link_off = apply(players[,1:10],1,min)
strong_link_off = apply(players[,1:10],1,max)
diff = offense/opp_defense
#make data matrix
data_model = data%>%mutate(offense = offense, opp_defense = opp_defense,
weak_link_off = weak_link_off,weak_link_def = weak_link_def)
#specify model
form = formula(xg_rate ~ offense + opp_defense + half + fatigue + diff +
extra_time + home + score_differential + weak_link_def + weak_link_off)
#fit model
model = lm(form,data = data_model,weights = period_length)
#add results to data matrix
data_model = data_model %>% mutate(E_xg = predict(model,data_model) * period_length)%>%
mutate(E_xg_rate = predict(model,data_model))
#aggregate results over teams
aggregated_data = data_model %>%
group_by(groups) %>%
summarise(
aggregate_xg = sum(xg, na.rm = TRUE),
aggregate_E_xg = sum(E_xg, na.rm = TRUE)
)
# Generate scatter plot
ggplot(aggregated_data, aes(x = aggregate_E_xg, y = aggregate_xg)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
labs(
title = paste("Scatterplot of Aggregated E[xG] vs xG (sigma =", round(sigma, 3), ")"),
x = "Aggregated E[xG]",
y = "Aggregated xG"
) +
theme_minimal()
# Generate scatter plot
ggplot(aggregated_data, aes(x = aggregate_E_xg, y = aggregate_xg)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
labs(
title = paste("Scatterplot of Aggregated E[xG] vs xG"),
x = "Aggregated E[xG]",
y = "Aggregated xG"
) +
theme_minimal()
data = sparrow::read_visiumHD()
bad_cells = which(Matrix::rowSums(data$counts) < 200)
data$coords = data$coords[-bad_cells,]
data$deconv = data$deconv[-bad_cells,]
data$niche = data$niche[-bad_cells,]
data$counts = data$counts[-bad_cells,]
dim(data$counts)
y = data$counts[,1]
X = data$niche
lambda = data$deconv
family = "spot poisson"
initialization = "full"
beta_0 = NULL
fix_coef = NULL
offset = log(Matrix::rowSums(data$counts))
min_deconv = 0.1
min_freq = 50
CT = NULL
weights = NULL
ct_cov_weights = NULL
max_gd_steps = 5000
learning_rate = 1
max_diff = 1-1e-6
intercept_col = NULL
t1 = Sys.time()
test = run_model(y = y,X = X,lambda = lambda,family = family,beta_0 =beta_0,fix_coef = fix_coef,
offset = offset,min_deconv =min_deconv,min_freq = min_freq,CT = CT, weights = weights,ct_cov_weights = ct_cov_weights,
max_gd_steps = max_gd_steps,learning_rate = learning_rate,max_diff = max_diff,intercept_col = intercept_col)
t1 = Sys.time()
test = spotglm:::run_model(y = y,X = X,lambda = lambda,family = family,beta_0 =beta_0,fix_coef = fix_coef,
offset = offset,min_deconv =min_deconv,min_freq = min_freq,CT = CT, weights = weights,ct_cov_weights = ct_cov_weights,
max_gd_steps = max_gd_steps,learning_rate = learning_rate,max_diff = max_diff,intercept_col = intercept_col)
print(Sys.time() - t1)
#Step 0: Pre-processing
if(is.null(weights)){
weights = rep(1,length(y))
}else if(length(weights)!= length(y)){
stop("Weights must be same length as observations")
}
if(is.null(ct_cov_weights)){
ct_cov_weights = rep(1,ncol(lambda))
}else if(length(ct_cov_weights)!= ncol(lambda)){
stop("Weights must be same length as number of columns of lambda")
}
#weight lambda by cov weights and normalize
if(is.null(ct_cov_weights) == F){
if(length(ct_cov_weights) != ncol(lambda)){
stop("Cell type covariate weights must be the same length as #col lambda")
}
lambda = sweep(lambda,2,ct_cov_weights,"*")
lambda = sweep(lambda,1,rowSums(lambda),"/")
lambda[is.na(lambda)] = 1/ncol(lambda)
}
#get family
if(family == "spot gaussian"){
model_family = "spot_gaussian"
sc_family = "gaussian"
}else if(family == "spot poisson"){
model_family = "spot_poisson"
sc_family = "poisson"
}else if(family == "spot negative binomial"){
model_family = "spot_negative_binomial"
sc_family = "poisson"
}else if(family == "spot binomial"){
model_family = "spot_binomial"
sc_family = "binomial"
}else{
stop("Family must be one of spot gaussian, spot poisson, spot negative binomial, or spot binomial")
}
if(is.null(fix_coef)){
fix_coef = matrix(FALSE,ncol(X),ncol(lambda))
}else if( (nrow(fix_coef)!= ncol(X)) |(ncol(fix_coef)!= ncol(lambda))){
stop("Fixed coefficients matrix must be of dimension ncol(X) by ncol(lambda)")
}
#Step 1: get initial beta
if(is.null(beta_0)){
beta_0 = matrix(0,ncol(X),ncol(lambda))
}else if( (nrow(beta_0)!= ncol(X)) |(ncol(beta_0)!= ncol(lambda))){
stop("Initial beta matrix must be of dimension ncol(X) by ncol(lambda)")
}
if(initialization == "intercept"){
initial_run= spotglm:::initialize_beta_intercept(y = y, X = X, lambda = lambda,beta = beta_0,
family = sc_family,offset = offset,
weights = weights,fix_coef = fix_coef,CT = CT,min_freq = min_freq,intercept_ind = intercept_col)
beta_0 = initial_run$beta_0
fix_coef = initial_run$fix_coef
}else if(initialization == "full"){
initial_run = spotglm:::initialize_beta_full(y = y, X = X, lambda = lambda,beta = beta_0,
family = sc_family,offset = offset,
weights = weights,fix_coef = fix_coef,CT = CT,min_freq = min_freq,intercept_ind = intercept_col)
beta_0 = initial_run$beta_0
fix_coef = initial_run$fix_coef
}else{
print("No initialization chosen. Must be one of intercept or full.")
}
beta_0
table(apply(lambda,1,function(x){which.max(x)}))
data = sparrow::read_visiumHD()
bad_cells = which(Matrix::rowSums(data$counts) < 50)
data$coords = data$coords[-bad_cells,]
data$deconv = data$deconv[-bad_cells,]
data$niche = data$niche[-bad_cells,]
data$counts = data$counts[-bad_cells,]
library(spotglm)
j=1
t1 = Sys.time()
y = data$counts[,j]
X = data$niche
lambda = data$deconv
family = "spot poisson"
initialization = "full"
beta_0 = NULL
fix_coef = NULL
offset = log(Matrix::rowSums(data$counts))
min_deconv = 0.1
min_freq = 50
CT = NULL
weights = NULL
ct_cov_weights = NULL
max_gd_steps = 5000
learning_rate = 1
max_diff = 1-1e-6
intercept_col = NULL
test = spotglm:::run_model(y = y,X = X,lambda = lambda,family = family,beta_0 =beta_0,fix_coef = fix_coef,
offset = offset,min_deconv =min_deconv,min_freq = min_freq,CT = CT, weights = weights,ct_cov_weights = ct_cov_weights,
max_gd_steps = max_gd_steps,learning_rate = learning_rate,max_diff = max_diff,intercept_col = intercept_col)
print(Sys.time() - t1)
test$niter
test$time
test$beta_est
## Step 0: Loading Data and Pre-processing
data = sparrow::read_visiumHD()
data$deconv[data$deconv < 0.1] = 0
data$deconv = t(apply(data$deconv,1,function(x){x/sum(x)}))
data$niche[data$niche < 0.1] = 0
data$niche = t(apply(data$niche,1,function(x){x/sum(x)}))
#remove spots with too few UMIs
bad_spots = which(rowSums(data$counts) < 20)
data$coords = data$coords[-bad_spots,]
data$niche = data$niche[-bad_spots,]
data$deconv = data$deconv[-bad_spots,]
data$counts = data$counts[-bad_spots,]
#make niche matrix has reference column
data$niche = data$niche[,-9]
data$niche = cbind(1,data$niche)
colnames(data$niche)[1] = "intercept"
freq = apply(data$niche,2,function(x){sum(x)})
bad_niche = which(freq<500)
if(length(bad_niche)> 0){
data$niche = data$niche[,-bad_niche]
}
library(spotglm)
library(sparrow)
colSums(data$niche)
sim_data = sparrow::simulate_data(n = 100000, nct = 9,effect_scale = 1/4, intercept_scale = 4,library_size = 5000, spot_ct = 2, p = 5, num_null = 2, prob_ct = NULL)
family = "spot poisson"
initialization = "intercept"
beta_0 = NULL
fix_coef = NULL
offset = rep(log(5000),length(sim_data$y))
min_deconv = 0.1
min_freq = 50
CT = NULL
weights = NULL
ct_cov_weights = NULL
n_epochs = 100
batch_size = 500
learning_rate = 1
max_diff = 1-1e-6
intercept_col = 1
y = sim_data$y
X = sim_data$X
lambda = sim_data$lambda
t1 = Sys.time()
sim_test = run_model(y = sim_data$y,X = sim_data$X,lambda = sim_data$lambda,family = "spot poisson",beta_0 =beta_0,fix_coef = fix_coef,
offset = offset,min_deconv =min_deconv,min_freq = min_freq,CT = CT, weights = weights,ct_cov_weights = ct_cov_weights,
n_epochs = n_epochs,batch_size= batch_size,learning_rate = learning_rate,max_diff = max_diff,intercept_col = c(1),initialization = initialization)
print(Sys.time() - t1)
plot(sim_data$beta[-1,],sim_test$beta_est[-1,])
abline(a = 0, b = 1, col = "red")
setwd("/Users/kmason/Desktop/Folders/research_projects/spatial/spotglm")
devtools::document()
devtools::install()
library(spotglm)
library(ggplot2)
library(patchwork)
library(dplyr)
data = spotglm::read_visium()
num_genes = ncol(data$counts)
res = vector("list",num_genes)
t1 = Sys.time()
#run spotGLM for each gene
for(j in c(1:num_genes)){
if(j%%1 == 0){
print(j)
print(Sys.time() - t1)
}
res[[j]] = spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 500)
}
num_genes = ncol(data$counts)
res = vector("list",num_genes)
t1 = Sys.time()
#run spotGLM for each gene
for(j in c(1:num_genes)){
if(j%%100 == 0){
print(j)
print(Sys.time() - t1)
}
res[[j]] = spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 500)
}
spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 500)
spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 32)
spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 128)
spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 32,n_epoch = 500)
spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 250)
num_genes = ncol(data$counts)
res = vector("list",num_genes)
t1 = Sys.time()
#run spotGLM for each gene
for(j in c(1:num_genes)){
if(j%%100 == 0){
print(j)
print(Sys.time() - t1)
}
res[[j]] = spotglm::run_model(y = data$counts[,j],X = data$niche, lambda = data$deconv,
family = "spot poisson",offset = log(data$library_size),
initialization = T,batch_size = 250)
}
names(res) = colnames(data$counts)
#get significant genes
sig_genes = compute_significance(input_list = res,cell_type = "stromal",
effect_name = "subclone_1",
beta_name = "beta_est",
standard_error_name = "stand_err_mat",
sided = 1,direction = "pos")
sig_genes = sig_genes%>%filter(!is.na(pval))
print("The following genes are (fibroblast,tumor subclone 1) niche differential")
print(rownames(sig_genes)[sig_genes$qval < 0.05])
#compute contrast test
sig_genes = compute_contrast_significance(input_list = res,
cell_type = "stromal",
effect_names = c("subclone_1","subclone_2"),
beta_name = "beta_est",covariance_name = "vcov",
sided = 1,direction = "pos")
sig_genes = sig_genes%>%filter(!is.na(pval))
m = paste0("The following genes are niche marker genes for fibroblasts near",
" tumor sublcone 1 vs tumor subclone 2")
print(m)
print(rownames(sig_genes)[sig_genes$qval < 0.05])
library(spotglm)
library(ggplot2)
library(dplyr)
library(patchwork)
data = spotglm::read_spatial_long_read()
data$deconv[data$deconv < 0.05] = 0
data$deconv = t(apply(data$deconv,1,function(x){x/sum(x)}))
region = apply(data$regions,1,function(x){colnames(data$regions)[which(x == 1)]})
library(ggplot2)
df <- data.frame(
x = data$coords[, 1],
y = data$coords[, 2],
region = region
)
ggplot(df, aes(x = x, y = y, color = region)) +
geom_point(size = 2) +
coord_fixed() +
theme_minimal() +
labs(title = "Spots by Region", color = "Region")
#Step 1: Intercept Model
#get number of genes
ngenes = ncol(data$total_gene_expression)
#initialize intercept estimates
intercept_estimate = vector("list",ngenes)
names(intercept_estimate) = colnames(data$total_gene_expression)
#iterate over each gene
for(j in c(1:ngenes)){
intercept_estimate[[j]]=spotglm::run_model(y = data$total_gene_expression[,j],
X = matrix(1,nrow(data$total_gene_expression),1),
lambda = data$deconv,
offset = log(data$library_size),
initialization = T,
family = "spot poisson",batch_size = 32, n_epoch = 500)
}
View(intercept_estimate)
#Step 2: Fit spot binomial model
isoform_DE = vector("list",ngenes)
names(isoform_DE) = colnames(data$total_gene_expression)
t1 = Sys.time()
for(j in c(1:ngenes)){
#get gene name
gene = names(isoform_DE)[j]
#get weights
weights = data$total_gene_expression[,gene]
#get covariate weights
ct_covariate_weights  = exp(intercept_estimate[[gene]]$beta_est)
#run model
isoform_DE[[j]] = spotglm::run_model(y = data$isoform_expression[[gene]][[1]],
X = data$regions,
lambda = data$deconv,
family = "spot binomial",
weights = weights,
ct_cov_weights = ct_covariate_weights,
initialization = T,batch_size = 32, n_epoch = 500)
}
print(Sys.time() - t1)
View(isoform_DE)
isoform_DE[["Myl6"]]
analysis_summary = list(isoform_DE = isoform_DE,intercept_estimate = intercept_estimate)
saveRDS(analysis_summary,"/Users/kmason/Desktop/Folders/research_projects/spatial/spatial_data/spotglm_data/long_read/analysis/results/isoform_DE.rds")
library(spotglm)
library(ggplot2)
library(dplyr)
library(patchwork)
setwd("/Users/kmason/Desktop/Folders/research_projects/spatial/spatial_data/spotglm_data/long_read/analysis/results")
#read in data
data = spotglm::read_spatial_long_read()
data$deconv[data$deconv < 0.05] = 0
data$deconv = t(apply(data$deconv,1,function(x){x/sum(x)}))
#read in regions
region = apply(data$regions,1,function(x){colnames(data$regions)[which(x == 1)]})
region = factor(colnames(data$regions))
region = region[apply(data$regions,1,function(x){which(x == 1)})]
#read in analysis results
isoform_DE_analysis = readRDS("isoform_DE.rds")
intercept_estimate = isoform_DE_analysis$intercept_estimate
isoform_DE = isoform_DE_analysis$isoform_DE
important_ct = isoform_DE_analysis$important_ct
### Step 3: Downstream Analysis: Contrast Test to Identify Isoform Switching Across Regions
#Store all contrast tests
all_contrast_tests = list()
cell_types = colnames(data$deconv)
regions = colnames(data$regions)
nregion = length(regions)
counter = 1
#test over all cell types and region pairs
for(ct in cell_types){
for(j in c(1:nregion)){
for(k in c(j:nregion)){
if(j==k){
next
}
region_A = regions[j]
region_B = regions[k]
#compute pvalues
pvals = suppressWarnings(spotglm::compute_contrast_significance(input_list = isoform_DE,
cell_type = ct,
effect_names = c(region_A,region_B),
beta_name = "beta_est",
covariance_name = "vcov",
sided = 2))
contrast_tests = data.frame(gene = pvals$name, cell_type = ct,
region_A = region_A, region_B = region_B,test_statistic = pvals$test_statistic,
pval = pvals$pval)
#add results to list
all_contrast_tests[[counter]] = contrast_tests
counter = counter + 1
}
}
}
combined_contrast_tests <- dplyr::bind_rows(all_contrast_tests)%>%
dplyr::filter(!is.na(pval))
#get significant switches
combined_contrast_tests$qval = p.adjust(combined_contrast_tests$pval,method = "BH")
significant_isoform_switches = combined_contrast_tests%>%filter(qval < 0.1)
View(significant_isoform_switches)
length(unique(significant_isoform_switches$gene))
table(significant_isoform_switches$cell_type)
setwd("/Users/kmason/Desktop/Folders/research_projects/spatial/spotglm")
devtools::document()
family = "negative binomial"
spot_family = "spot negative binomial"
dispersion = 1
lib_size = 500
dispersion = 5
data = sparrow::simulate_data(n = 1e5, nct = 8,family = family,
effect_range = c(-0.2,0.2),
min_effect = 0.05,
intercept_range = c(-6,-4),
library_size = lib_size, spot_ct = 2,
p = 8,num_null = 2,prob_ct = NULL,dispersion = dispersion)
colnames(data$X) = paste0("effect_",c(1:ncol(data$X))-1)
colnames(data$X)[1] = "intercept"
colnames(data$lambda) = paste0("cell_type_",c(1:ncol(data$lambda)))
if(spot_family == "spot binomial"){
model = spotglm::run_model(y = data$y,X = data$X,lambda = data$lambda,
family = spot_family,weights=rep(lib_size,
length(data$y)),n_epochs = 100,batch_size= 32,
learning_rate = 10,max_diff = 1-1e-6,
initialization = T)
}else{
model = spotglm::run_model(y = data$y,X = data$X,lambda = data$lambda,
family = spot_family,offset=rep(log(lib_size),
length(data$y)),n_epochs = 100,batch_size = 32,
learning_rate = 1,max_diff = 1-1e-6,
initialization = T)
}
setwd("/Users/kmason/Desktop/Folders/research_projects/spatial/spotglm")
devtools::document()
