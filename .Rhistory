lambda = sim_data$lambda
t1 = Sys.time()
sim_test = run_model(y = sim_data$y,X = sim_data$X,lambda = sim_data$lambda,family = "spot poisson",beta_0 =beta_0,fix_coef = fix_coef,
offset = offset,min_deconv =min_deconv,min_freq = min_freq,CT = CT, weights = weights,ct_cov_weights = ct_cov_weights,
n_epochs = n_epochs,batch_size= batch_size,learning_rate = learning_rate,max_diff = max_diff,intercept_col = c(1),initialization = initialization)
print(Sys.time() - t1)
plot(sim_data$beta[-1,],sim_test$beta_est[-1,])
abline(a = 0, b = 1, col = "red")
setwd("/Users/kmason/Desktop/sparrow")
devtools::document()
devtools::install()
setwd("/Users/kmason/Desktop/Folders/research_projects/spatial/spotglm")
devtools::document()
devtools::install()
library(sparrow)
library(ggplot2)
library(dplyr)
data = read_merfish()
data$regions = model.matrix(~ regions - 1,
data = data.frame(regions = data$regions))
data$CT = model.matrix(~ CT - 1, data = data.frame(CT = data$CT))
#Sample out data to make downstream analysis faster
ind = c(1:ncol(data$counts))[1:300000]
data$counts = data$counts[,ind]
data$regions = data$regions[ind,]
data$CT = data$CT[ind,]
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff),
min_freq = 250)
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
target_standard_errors = sparrow::compute_target_standard_error(X = expanded_X,
min_effect = 0.05,target_power_approx = 0.99)
colSums(expanded_X)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
expanded_X = expanded_X[,colSums(expanded_X) > 500]
```
colSums(expanded_X) > 500
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
expanded_X = expanded_X[,colSums(expanded_X) > 500]
ncol(expanded_X)
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
expanded_X = expanded_X[,colSums(expanded_X) > 100]
ncol(exoanded)X
ncol(expanded_X)
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
expanded_X = expanded_X[,colSums(expanded_X) > 250]
selected_indices = sparrow::data_selection(X = t(expanded_X),
data_size = 300000,min_SE = target_standard_errors,
log = TRUE,period = 10000)
selected_indices = sparrow::data_selection(X = t(expanded_X),
max_data_size = 300000,min_SE = target_standard_errors,
log = TRUE,period = 10000)
selected_indices = sparrow::data_selection(X = t(expanded_X),
max_data_size = 300000,
min_standard_error = target_standard_errors,
log = TRUE,period = 10000)
target_standard_errors = sparrow::compute_target_standard_error(X = expanded_X,
min_effect = 0.05,target_power_approx = 0.99)
selected_indices = sparrow::data_selection(X = t(expanded_X),
max_data_size = 300000,
min_standard_error = target_standard_errors,
log = TRUE,period = 10000)
selected_indices = selected_indices[is.na(selected_indices) == F]
print(paste0("Cells Chosen: ",length(selected_indices)))
#get region on
nregion = ncol(data$regions)
nCT = ncol(data$CT)
#get number of genes
ngene = nrow(data$counts)
#get library size of cells
spot_size = colSums(data$counts)
#save results to a list
res = list()
#start time
t1 = Sys.time()
for(i in c(1:ngene)){
if(i %%100 == 0){
print(paste0("Iteration ",i," out of ",ngene))
print(Sys.time() - t1)
}
#save beta
beta = matrix(NA,nregion ,nCT)
#get dimnames of beta
colnames(beta) = colnames(data$CT)
rownames(beta) = colnames(data$regions)
#standard error matrix
SE = matrix(NA,nregion,nCT)
colnames(SE) = colnames(data$CT)
rownames(SE) = colnames(data$regions)
#get counts
Y = data$counts[i,]
for(j in c(1:nCT)){
#get cells that correspond to that cell type
cells = which(data$CT[,j] == 1)
#get covariate matrix
X = data$regions[cells,]
#subset covariate matrix by valid
ct_ind = which(valid_cov[,j] == 1)
X = X[,ct_ind]
#get response
y = Y[cells]
#get offset
offset_cells = log(spot_size)[cells]
#fit model
model = glm(y~X-1+offset(offset_cells),family = "poisson")
#save beta
beta[ct_ind,j] = coef(model)
#save standard errors
SE[ct_ind,j] = sqrt(diag(vcov(model)))
}
#save results
res[[i]] = list(beta = beta,SE = SE)
}
#get region on
nregion = ncol(data$regions)
nCT = ncol(data$CT)
#get number of genes
ngene = nrow(data$counts)
#get library size of cells
spot_size = colSums(data$counts)
#save results to a list
res = list()
#start time
t1 = Sys.time()
for(i in c(1:ngene)){
if(i %%100 == 0){
print(paste0("Iteration ",i," out of ",ngene))
print(Sys.time() - t1)
}
#save beta
beta = matrix(NA,nregion ,nCT)
#get dimnames of beta
colnames(beta) = colnames(data$CT)
rownames(beta) = colnames(data$regions)
#standard error matrix
SE = matrix(NA,nregion,nCT)
colnames(SE) = colnames(data$CT)
rownames(SE) = colnames(data$regions)
#get counts
Y = data$counts[i,]
for(j in c(1:nCT)){
#get cells that correspond to that cell type
cells = which(data$CT[,j] == 1)
#get covariate matrix
X = data$regions[cells,]
#subset covariate matrix by valid
#ct_ind = which(valid_cov[,j] == 1)
#X = X[,ct_ind]
#get response
y = Y[cells]
#get offset
offset_cells = log(spot_size)[cells]
#fit model
model = glm(y~X-1+offset(offset_cells),family = "poisson")
#save beta
beta[ct_ind,j] = coef(model)
#save standard errors
SE[ct_ind,j] = sqrt(diag(vcov(model)))
}
#save results
res[[i]] = list(beta = beta,SE = SE)
}
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
expanded_X = expanded_X[,colSums(expanded_X) > 250]
valid_cov = matrix(colSums(expanded_X) > 250,ncol(data$regions),ncol(data$CT))
#get gene totals and total counts
gene_totals = rowSums(data$counts)
total_UMI = sum(data$counts)
#get good cutoff value for
cutoff = quantile(log(gene_totals/total_UMI),0.75)
#make expanded covariate matrix
expanded_X = sparrow::expand_covariate_matrix(X = data$regions, lambda = data$CT,
family = "poisson",lib_size = colSums(data$counts),
min_reads_per_1000 = 1000*exp(cutoff))
valid_cov = matrix(colSums(expanded_X) > 250,ncol(data$regions),ncol(data$CT))
expanded_X = expanded_X[,colSums(expanded_X) > 250]
selected_indices = sparrow::data_selection(X = t(expanded_X),
max_data_size = 300000,min_standard_error = target_standard_errors,
log = TRUE,period = 10000)
selected_indices = selected_indices[is.na(selected_indices) == F]
print(paste0("Cells Chosen: ",length(selected_indices)))
#get region on
nregion = ncol(data$regions)
nCT = ncol(data$CT)
#get number of genes
ngene = nrow(data$counts)
#get library size of cells
spot_size = colSums(data$counts)
#save results to a list
res = list()
#start time
t1 = Sys.time()
for(i in c(1:ngene)){
if(i %%100 == 0){
print(paste0("Iteration ",i," out of ",ngene))
print(Sys.time() - t1)
}
#save beta
beta = matrix(NA,nregion ,nCT)
#get dimnames of beta
colnames(beta) = colnames(data$CT)
rownames(beta) = colnames(data$regions)
#standard error matrix
SE = matrix(NA,nregion,nCT)
colnames(SE) = colnames(data$CT)
rownames(SE) = colnames(data$regions)
#get counts
Y = data$counts[i,]
for(j in c(1:nCT)){
#get cells that correspond to that cell type
cells = which(data$CT[,j] == 1)
#get covariate matrix
X = data$regions[cells,]
#subset covariate matrix by valid
ct_ind = which(valid_cov[,j] == 1)
X = X[,ct_ind]
#get response
y = Y[cells]
#get offset
offset_cells = log(spot_size)[cells]
#fit model
model = glm(y~X-1+offset(offset_cells),family = "poisson")
#save beta
beta[ct_ind,j] = coef(model)
#save standard errors
SE[ct_ind,j] = sqrt(diag(vcov(model)))
}
#save results
res[[i]] = list(beta = beta,SE = SE)
}
#start time
print(Sys.time() - t1)
#get region on
nregion = ncol(data$regions)
nCT = ncol(data$CT)
#get number of genes
ngene = nrow(data$counts)
#get library size of cells
spot_size = colSums(data$counts)
#save results to a list
res_subsample = list()
t1 = Sys.time()
for(i in c(1:ngene)){
if(i %%100 == 0){
print(paste0("Iteration ",i," out of ",ngene))
print(Sys.time() - t1)
}
#save beta
beta = matrix(NA,nregion ,nCT)
#get dimnames of beta
colnames(beta) = colnames(data$CT)
rownames(beta) = colnames(data$regions)
#standard error matrix
SE = matrix(NA,nregion,nCT)
colnames(SE) = colnames(data$CT)
rownames(SE) = colnames(data$regions)
#get counts
Y = data$counts[i,]
for(j in c(1:nCT)){
#get cells that correspond to that cell type
cells = selected_indices[data$CT[selected_indices,j] == 1]
#get covariate matrix
X = data$regions[cells,]
#subset covariate matrix by valid
ct_ind = which(valid_cov[,j] == 1)
X = X[,ct_ind]
#get response
y = Y[cells]
#get offset
offset_cells = log(spot_size)[cells]
#fit model
model = glm(y~X-1+offset(offset_cells),family = "poisson")
#save beta
beta[ct_ind,j] = coef(model)
#save standard errors
SE[ct_ind,j] = sqrt(diag(vcov(model)))
}
#save results
res_subsample[[i]] = list(beta = beta,SE = SE)
}
contrast_test = function(beta,SE,upper = T){
pvals = matrix(NA,length(beta),length(beta))
for(j in c(1:length(beta))){
diff = beta[j] - beta
diff_SE = sqrt(SE[j]^2 + SE^2)
pvals[,j] = 2*(1-pnorm(abs(diff/diff_SE)))
}
if(upper){
pvals[upper.tri(pvals)] <- NA
}
diag(pvals) = NA
return(pvals)
}
#get pvalue list for full data and subsampled data
pvalue_subsample = c()
pvalue_full = c()
for(j in c(1:ngene)){
full_result = res[[j]]
subsample_result = res_subsample[[j]]
nCT = ncol(full_result$beta)
for(k in c(1:nCT)){
p_sub = contrast_test(full_result$beta[,k],full_result$SE[,k])
p_full = contrast_test(subsample_result$beta[,k],subsample_result$SE[,k])
pvalue_subsample = c(pvalue_subsample,p_sub)
pvalue_full = c(pvalue_full,p_full)
}
}
pvalue_subsample_adj = p.adjust(pvalue_subsample, method = "BH")
pvalue_full_adj = p.adjust(pvalue_full, method = "BH")
CT_names = colnames(res[[1]]$beta)
N = min(1000,sum(pvalue_full_adj[is.na(pvalue_full_adj)==F] <= 0.05))
set.seed(110)
Nind = 1000
Nindices = floor(seq(1,N,length.out = Nind))
ordered_pvals = sort(pvalue_full_adj[is.na(pvalue_full_adj)==F])
ordered_pvals = ordered_pvals[ordered_pvals < 0.05]
pval_inds = sort(c(1,sample(c(2:length(ordered_pvals)),N-1,replace = F)))
log_p = log(pvalue_full_adj[is.na(pvalue_full_adj)==F],10)
log_p = log_p[is.infinite(log_p) == F]
min_log_p = min(log_p)
#get numerator and denominator in recall
recall = rep(NA,Nind)
NUM = rep(0,Nind)
DEN = rep(0,Nind)
C = rep(0,Nind)
for(k in c(1:Nind)){
#get cutoff value
cutoff = max(min(log_p),ordered_pvals[pval_inds[k]])
standard_sig = (pvalue_full_adj <= cutoff & is.na(pvalue_subsample_adj) == F)
query_sig = (pvalue_subsample_adj <= 0.05)
NUM[k] =  sum(standard_sig * query_sig,na.rm = T)
DEN[k] = sum(standard_sig,na.rm = T)
recall[k] = NUM[k]/DEN[k]
C[k] = log(cutoff,10)
if(is.infinite(C[k])){
C[k] = min(log_p)
}
}
# Example data
plot_data <- data.frame(
C = C,                # Replace with your actual 'C' values
recall = recall # Replace with your actual 'recall' values
)
# Create the plot
PLOT = ggplot(plot_data, aes(x = C, y = recall)) +
geom_point() +  # Scatter points
geom_line() +   # Optional: Connect points with lines
scale_y_continuous(
limits = c(0, 1),            # Set y-axis limits
breaks = seq(0, 1, by = 0.1) # Add y-axis ticks
) +
theme_minimal() +  # Use a clean theme
labs(
x = "Full Data Log Q-value Cutoff",          # Label for the x-axis
y = "Recall",     # Label for the y-axis
title = paste0("Recall of Subsetted Data: ")
) +
theme(
panel.grid.major = element_line(color = "grey80"), # Add a grid
panel.grid.minor = element_blank()                 # Optional: Hide minor grids
)
print(PLOT)
#compute type 1 error
standard_null = (pvalue_full_adj > 0.05 & is.na(pvalue_subsample_adj) == F)
query_sig = (pvalue_subsample_adj <= 0.05)
type_1_error = sum(query_sig * standard_null,na.rm = T)/sum(standard_null,na.rm = T)
#print
print(paste0("Type 1 error rate: ",round(type_1_error,2)))
library(sparrow)
library(spotglm)
data = sparrow::simulate_data(n = 1e5, nct = 8,effect_range = (-0.2,0.2),min_effect = 0.05,
data = sparrow::simulate_data(n = 1e5, nct = 8,effect_range = c(-0.2,0.2),min_effect = 0.05,
intercept_range = c(-6,-4),
library_size = 1000, spot_ct = 2,
p = 8,num_null = 2,prob_ct = NULL)
expanded_X = sparrow::expand_covariate_matrix(X = data$X, lambda = data$lambda,
family = "poisson",lib_size = 1000,
min_reads_per_1000 = 1000*exp(-5))
target_standard_errors = sparrow::compute_target_standard_error(X = expanded_X,
min_effect = 0.05,target_power_approx = 0.99)
selected_indices = sparrow::data_selection(X = t(expanded_X),
data_size = 80000,min_SE = target_standard_errors,
log = TRUE,period = 5000)
selected_indices = sparrow::data_selection(X = t(expanded_X),
max_data_size = 80000,
min_standard_error = target_standard_errors,
log = TRUE,period = 5000)
selected_indices = selected_indices[is.na(selected_indices) == F]
print(paste0("#Cells Subsampled: ", length(selected_indices)))
nsim = 25
full_power = rep(NA,nsim)
subset_power = rep(NA,nsim)
full_time = rep(NA,nsim)
subset_time = rep(NA,nsim)
t1 = Sys.time()
for(j in c(1:nsim)){
#simulate new response vector
expected_value = spotglm::spot_poisson$predict(X = data$X,beta = data$beta,
lambda = data$lambda,
offset = rep(log(1000),
length(data$y)))
expected_value = expected_value$total
data$y = rpois(1e5,lambda = expected_value)
#run spotglm on original dataset
model_full = spotglm::run_model(y = data$y, X = data$X, lambda = data$lambda,
offset = rep(log(1000),length(data$y)),
family = "spot poisson",initialization = "intercept",
intercept_col = 1,batch_size = 500,n_epochs = 100,
improvement_threshold = 1e-6,max_conv = 20)
#run spotglm on subsetted data
model_subset = spotglm::run_model(y = data$y[selected_indices],
X = data$X[selected_indices,],
lambda = data$lambda[selected_indices,],
offset=rep(log(1000),length(data$y))[selected_indices],
family = "spot poisson",initialization = "intercept",
intercept_col = 1,batch_size = 500,n_epochs = 100,
improvement_threshold = 1e-6,max_conv = 20)
#compute power
full_sig = abs(model_full$beta_est/model_full$stand_err_mat)>1.96
subset_sig = abs(model_subset$beta_est/model_subset$stand_err_mat)>1.96
full_power[j] = sum(full_sig * (1-data$null_beta))/sum(1-data$null_beta)
subset_power[j] = sum(subset_sig * (1-data$null_beta))/sum(1-data$null_beta)
#sompute time
full_time[j] = model_full$time
subset_time[j] = model_subset$time
}
nsim = 25
full_power = rep(NA,nsim)
subset_power = rep(NA,nsim)
full_time = rep(NA,nsim)
subset_time = rep(NA,nsim)
t1 = Sys.time()
for(j in c(1:nsim)){
#simulate new response vector
expected_value = spotglm::spot_poisson$predict(X = data$X,beta = data$beta,
lambda = data$lambda,
offset = rep(log(1000),
length(data$y)))
expected_value = expected_value$total
data$y = rpois(1e5,lambda = expected_value)
#run spotglm on original dataset
model_full = spotglm::run_model(y = data$y, X = data$X, lambda = data$lambda,
offset = rep(log(1000),length(data$y)),
family = "spot poisson",initialization = T,
batch_size = 500,n_epochs = 100,
improvement_threshold = 1e-6,max_conv = 20)
#run spotglm on subsetted data
model_subset = spotglm::run_model(y = data$y[selected_indices],
X = data$X[selected_indices,],
lambda = data$lambda[selected_indices,],
offset=rep(log(1000),length(data$y))[selected_indices],
family = "spot poisson",initialization = T,
batch_size = 500,n_epochs = 100,
improvement_threshold = 1e-6,max_conv = 20)
#compute power
full_sig = abs(model_full$beta_est/model_full$stand_err_mat)>1.96
subset_sig = abs(model_subset$beta_est/model_subset$stand_err_mat)>1.96
full_power[j] = sum(full_sig * (1-data$null_beta))/sum(1-data$null_beta)
subset_power[j] = sum(subset_sig * (1-data$null_beta))/sum(1-data$null_beta)
#sompute time
full_time[j] = model_full$time
subset_time[j] = model_subset$time
}
print(Sys.time() - t1)
print(paste0("Mean Power on Full Data: ", round(mean(full_power),3)))
print(paste0("Mean Power on Subsetted Data: ", round(mean(subset_power),3)))
